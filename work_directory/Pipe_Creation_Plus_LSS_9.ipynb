{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f91c172e",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0595c3",
   "metadata": {},
   "source": [
    "This notebook updates Pipe_Creation_Plus_LSS_8.ipynb\n",
    "\n",
    "(Based on Illustris_Zhang_Method/batch_jobs/batch_scripts/make_pipes_2.py code).\n",
    "\n",
    "- It builds upon the Zhang+20 method of creating DMs from the TNG simulation.\n",
    "- It improves upon this by correcting ElectronAbundance in star-forming regions using the Pakmor+18 method allowing them to be used. To do this it calculates the warm-phase gas mass fraction W (=1-X, where X is from Marinacci+17)\n",
    "- It identifies LSS using the Artale+21 method.\n",
    "- It inserts code developed to load snapshots partwise to handle larger simulations\n",
    "- It saves output data to file as it is created, which allows it to be stopped and resumed rather than being started from scratch.\n",
    "- It removes unecessary tests and plots and incorporates all code into a single cell, which can be copied into a .py file to be run as a batch job.\n",
    "- It stores Particle ID and location information which can be used to calculate halo impact factors along tthe line of sight.\n",
    "- It contains an option for multiprocessing different pipes on multiple cpus simultaneously to speed up pipe creation\n",
    "- It cleans up Pipe_Creation_Plus_LSS_6.ipynb, removing much of the testing.\n",
    "- It utilises matchlists which are now stored in /ptmp/ and saved in chunks to allow larger simulations (e.g. TNG300-1) to be processed\n",
    "\n",
    "Notes: \n",
    "\n",
    "- The lines of code which save pipes have been commented out in this version of the code in order not to overwrite existing file\n",
    "- When running on a Jupyter notebook, it seems to begin failing after requesting around 6-7+ cpus simultaneously. This may be an issue with the interactive nodes. Hopeefully, in a script we should be able to use many more (50-70)\n",
    "\n",
    "ELECTRON DENSITY OF SFR CODE ARCHIVE\n",
    "\n",
    "raven:/u/cwalker/Illustris_FRB_Project/oct2_2021_output/IGM_new_scripts/job_raven.py, raven:/u/cwalker/Illustris_FRB_Project/charlie_TNG_lib/charlie_TNG_tools.py\n",
    "PAPERS: Marinacci+17: https://arxiv.org/abs/1610.01594, Pakmor+18: https://arxiv.org/abs/1807.02113\n",
    "\n",
    "PIPE CREATION CODE ARCHIVE\n",
    "\n",
    "raven:/u/cwalker/Illustris_Zhang_Method/Pipe_Creation_Test.ipynb, raven:/u/cwalker/Illustris_Zhang_Method/Pipe_Creation_Plus_LSS.ipynb, raven:/u/cwalker/Illustris_Zhang_Method/Pipe_Creation_Plus_LSS.ipynb\n",
    "PAPERS: Zhang+20: https://arxiv.org/abs/2011.14494\n",
    "\n",
    "LSS CLASSIFICATION CODE ARCHIVE\n",
    "\n",
    "raven:/u/cwalker/Illustris_FRB_Project/git_Illustris_uploads/mass_fraction_plots/artale_test_121121/SCRIPT_Cel_Auto.py, raven:/u/cwalker/Illustris_FRB_Project/yt-artale-constants.ipynb\n",
    "PAPERS: Artale+21: https://arxiv.org/abs/2102.01092\n",
    "\n",
    "PARTWISE SIMULATION LOADING ARCHIVE\n",
    "\n",
    "raven:/u/cwalker/Illustris_Zhang_Method/Test_Subset_Loading.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdb156e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "491e5828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notes\n",
    "#This is a script for use as a batch job\n",
    "#It is an upgade of make_pipes.py.\n",
    "#It incorporates updated code for impact factor analysis\n",
    "#and multiprocessing from ../Illustris_Zhang_Method/Pipe_Creation_Plus_LSS_8.ipynb\n",
    "\n",
    "#imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import multiprocessing as m\n",
    "import illustris_python as il\n",
    "\n",
    "from contextlib import closing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from numpy import random as rand\n",
    "from astropy import constants as c\n",
    "from charlie_TNG_tools import temp2u\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.stats import binned_statistic_dd\n",
    "from astropy.cosmology import Planck15 as cosmosource"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d477075",
   "metadata": {},
   "source": [
    "# Parse command line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddb5a64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #parse command line arguments#\n",
    "# cla = sys.argv\n",
    "# n_inputs = 4\n",
    "\n",
    "# if len(cla)!=n_inputs+1:\n",
    "#     print(\"Error! {0} arguments required. {1} arguments provided.\".format(n_inputs,len(cla)))\n",
    "#     print(\"Exiting script.\")\n",
    "#     sys.exit()\n",
    "\n",
    "# else:\n",
    "#     sim_to_use = str(cla[1])# the simulation to use, e.g. 'TNG50-4'\n",
    "#     pipes_per_snap = int(cla[2]) #the number of pipes to create per snapshot, e.g. 5125\n",
    "#     snap_to_process = int(cla[3]) #the snapshot number to process, e.g. 99\n",
    "#     cpus_to_use = int(cla[4]) #the number of simultaneous cores to load data with.\n",
    "    \n",
    "\n",
    "    \n",
    "sim_to_use = 'TNG50-4'\n",
    "pipes_per_snap = 5126\n",
    "snap_to_process = 99\n",
    "cpus_to_use = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cd94c7",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aab93624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "\n",
    "def gadgetDens2SI(dens):\n",
    "    \"\"\"\n",
    "    Original Artale function to convert TNG densities to SI units\n",
    "\n",
    "    INPUTSRETURNS:\n",
    "\n",
    "    dens : [values] densities from TNG\n",
    "\n",
    "    RETURNS:\n",
    "\n",
    "    dens converted to SI units\n",
    "    \"\"\"\n",
    "    return dens*1E10*cel_Msol_si/cel_hubble/(cel_kpc_si/cel_hubble)**3\n",
    "\n",
    "def TNG_Dens2SI(dens):\n",
    "    \"\"\"\n",
    "    Like gadgetDens2SI but using astropy values for constants\n",
    "    Strips result of units\n",
    "    Developed in raven:/u/cwalker/Illustris_FRB_Project/yt-artale-constants.ipynb\n",
    "\n",
    "\n",
    "    INPUTSRETURNS:\n",
    "\n",
    "    dens : [values] densities from TNG\n",
    "\n",
    "    RETURNS:\n",
    "\n",
    "    dens converted to SI units\n",
    "    \"\"\"\n",
    "    return dens*1E10*c.M_sun.to('kg').value/cosmosource.h/(c.kpc.to('m').value/cosmosource.h)**3\n",
    "\n",
    "def TNG_Dens2SI_astropy(dens):\n",
    "    \"\"\"\n",
    "    Like TNG_Dens2SI but does not strip result of units.\n",
    "    Developed in raven:/u/cwalker/Illustris_FRB_Project/yt-artale-constants.ipynb\n",
    "\n",
    "\n",
    "    INPUTSRETURNS:\n",
    "\n",
    "    dens : [values] densities from TNG\n",
    "\n",
    "    RETURNS:\n",
    "\n",
    "    dens converted to SI units\n",
    "    \"\"\"\n",
    "\n",
    "    return dens*1E10*c.M_sun.to('kg')/cosmosource.h/(c.kpc.to('m')/cosmosource.h)**3\n",
    "\n",
    "\n",
    "def pSplitRange(indrange, numProcs, curProc, inclusive=False):\n",
    "    \"\"\" Divide work for embarassingly parallel problems. \n",
    "    Accept a 2-tuple of [start,end] indices and return a new range subset.\n",
    "    If inclusive==True, then assume the range subset will be used e.g. as input to snapshotSubseet(),\n",
    "    which unlike numpy convention is inclusive in the indices.\"\"\"\n",
    "    assert len(indrange) == 2 and indrange[1] > indrange[0]\n",
    "\n",
    "    if numProcs == 1:\n",
    "        if curProc != 0:\n",
    "            raise Exception(\"Only a single processor but requested curProc>0.\")\n",
    "        return indrange\n",
    "\n",
    "    # split array into numProcs segments, and return the curProc'th segment\n",
    "    splitSize = int(np.floor( (indrange[1]-indrange[0]) / numProcs ))\n",
    "    start = indrange[0] + curProc*splitSize\n",
    "    end   = indrange[0] + (curProc+1)*splitSize\n",
    "\n",
    "    # for last split, make sure it takes any leftovers\n",
    "    if curProc == numProcs-1:\n",
    "        end = indrange[1]\n",
    "\n",
    "    if inclusive and curProc < numProcs-1:\n",
    "        # not for last split/final index, because this should be e.g. NumPart[0]-1 already\n",
    "        end -= 1\n",
    "\n",
    "    return [start,end]\n",
    "\n",
    "\n",
    "def loadSubset(simPath, snap, partType, fields, chunkNum=0, totNumChunks=1):\n",
    "    \"\"\" \n",
    "    Load part of a snapshot.\n",
    "    frm Dylan Nelson: https://www.tng-project.org/data/forum/topic/203/loading-the-tng100-1-data/\n",
    "    \"\"\"\n",
    "    nTypes = 6\n",
    "    ptNum = il.util.partTypeNum(partType)\n",
    "\n",
    "    with h5py.File(il.snapshot.snapPath(simPath,snap),'r') as f:\n",
    "        numPartTot = il.snapshot.getNumPart( dict(f['Header'].attrs.items()) )[ptNum]\n",
    "\n",
    "    # define index range\n",
    "    indRange_fullSnap = [0,numPartTot-1]\n",
    "    indRange = pSplitRange(indRange_fullSnap, totNumChunks, chunkNum, inclusive=True)\n",
    "\n",
    "    # load a contiguous chunk by making a subset specification in analogy to the group ordered loads\n",
    "    subset = { 'offsetType'  : np.zeros(nTypes, dtype='int64'),\n",
    "               'lenType'     : np.zeros(nTypes, dtype='int64') }\n",
    "\n",
    "    subset['offsetType'][ptNum] = indRange[0]\n",
    "    subset['lenType'][ptNum]    = indRange[1]-indRange[0]+1\n",
    "\n",
    "    # add snap offsets (as required)\n",
    "    with h5py.File(il.snapshot.offsetPath(simPath,snap),'r') as f:\n",
    "        subset['snapOffsets'] = np.transpose(f['FileOffsets/SnapByType'][()])\n",
    "\n",
    "    # load from disk\n",
    "    r = il.snapshot.loadSubset(simPath, snap, partType, fields, subset=subset)\n",
    "\n",
    "    return r\n",
    "\n",
    "def process_sim_chunk(snap_number,basePath,sim_to_use,nSubLoads,chunkIDs,T_h,T_c,c1s,c2e):\n",
    "    \"\"\"\n",
    "    processes part of the simulation on a single cpu. Is fed by unwrap_package().\n",
    "    this is specifically for pipes going along the x-axis from 0 to box length.\n",
    "    \n",
    "    \n",
    "    INPUTS:\n",
    "    \n",
    "    snap_number : [int] the snapshot number of the simulation to be processed\n",
    "    basePath    : [str] the path to the simulation data to be processed\n",
    "    sim_to_use  : [str] the simulation to be processed\n",
    "    nSubLoads   : [int] the total number of parts the simulation will be split into\n",
    "    chunkIDs    : [array of ints] the id numbers of the chunks of simulation to be processed on this cpu\n",
    "    T_h         : [= 10**7]  hot phase gase temperature [Kelvin] \n",
    "    T_c         : [= 10**3]  cold phase gas temperature [Kelvin]\n",
    "    c1s         : [0,pipe_width/2,pipe_width/2] coordinates at upper right of pipe start\n",
    "    c2e         : [0,-pipe_width/2,-pipe_width/2] coordinates at lower left of pipe end\n",
    "    \n",
    "    \n",
    "    RETURNS:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    verbose = False\n",
    "    \n",
    "    for i in range(len(chunkIDs)): #loop over all chunk ids\n",
    "        \n",
    "        chunkID = chunkIDs[i] # the chunk ID to be processed\n",
    "        \n",
    "        if verbose == True:\n",
    "            print('Verbose mode check: chunkID = {0}'.format(chunkID))\n",
    "        \n",
    "        temp_dict = {} #initialise dictionary to store data for this chunk in\n",
    "        \n",
    "        #the name of the file dictionary for this chunk will be stored in\n",
    "        part_outdata_filename = '/u/cwalker/Illustris_Zhang_Method/temp_chunks/sim_{0:02d}_snap_{1:03d}_cID_{2}.npy'.format(snap_number,chunkID,sim_to_use) \n",
    "        \n",
    "        if verbose == True:\n",
    "            print('Verbose mode check: store data at = {0}'.format(part_outdata_filename))\n",
    "            \n",
    "            \n",
    "        #initialise arrays to hold the desired information about\n",
    "        #the simulation cells in this part of the simulation\n",
    "\n",
    "        #pipe_cell_coords_part=[]\n",
    "        #pipe_cell_dens_part = []\n",
    "        #pipe_cell_elab_part=[]\n",
    "        #pipe_cell_sfr_part=[]\n",
    "        #pipe_cell_dark_part = []\n",
    "        #pipe_cell_warm_part=[]\n",
    "        #pipe_cell_pIDs_part=[]\n",
    "\n",
    "        ###########################\n",
    "        #load the partial data set#\n",
    "        ###########################\n",
    "\n",
    "        data = loadSubset(basePath,snap_number, 'gas', fields,chunkNum=chunkID, totNumChunks=nSubLoads)\n",
    "        \n",
    "        if verbose == True:\n",
    "            print('Verbose mode check: data = {0}'.format(data))\n",
    "\n",
    "        #####################################\n",
    "        #create warm-phase gas mass fraction#\n",
    "        #####################################\n",
    "\n",
    "        density = data['Density'] #the density values along the light ray in gcm**-3\n",
    "        sfr     = data['StarFormationRate'] #the star formation rate along the light ray in g/s\n",
    "        ie      = data['InternalEnergy'] #the internal energy along the light ray in erg/g\n",
    "        ea      = data['ElectronAbundance'] #the electron abundance along the light ray\n",
    "        #calculate x and w, cold and warm phase gas mass fractions\n",
    "        x_frac = (temp2u(T_h,ea)-ie)/(temp2u(T_h,ea)-temp2u(T_c,ea)) #cold phase mass fraction\n",
    "        w_frac = 1 - x_frac # warm phase mass fraction\n",
    "        #only modify electron abundance if sfr = 0\n",
    "        w_frac[np.where(sfr==0)]=1\n",
    "        data['Warm']=w_frac    \n",
    "        \n",
    "        if verbose == True:\n",
    "            print('Verbose mode check: w frac = {0}'.format(data['Warm']))\n",
    "\n",
    "        ########################\n",
    "        #get cells in this pipe#\n",
    "        ########################\n",
    "\n",
    "        yz_pts = data['Coordinates'][:,[1,2]]\n",
    "        ur = c1s[1:] #upper right of pipe start (y and z only)\n",
    "        ll = c2e[1:] #lower left of pipe end (y and z only)\n",
    "        inidx = np.all((ll <= yz_pts) & (yz_pts <= ur), axis=1) #indexes of cells in pipe\n",
    "        \n",
    "        if verbose == True:\n",
    "            print('Verbose mode check: inidx = {0}'.format(inidx))\n",
    "\n",
    "        ###########################\n",
    "        #get data of cells in pipe#\n",
    "        ###########################\n",
    "\n",
    "        #pipe_cell_coords_part.append(data['Coordinates'][inidx])       #coordinates [ckpc/h]\n",
    "        pipe_cell_coords_part=data['Coordinates'][inidx]      #coordinates [ckpc/h]\n",
    "\n",
    "        #pipe_cell_dens_part.append(data['Density'][inidx])           #densities [(1e10Msun/h)/(ckpc/h)**3]\n",
    "        pipe_cell_dens_part=data['Density'][inidx]          #densities [(1e10Msun/h)/(ckpc/h)**3]\n",
    "\n",
    "        #pipe_cell_elab_part.append(data['ElectronAbundance'][inidx]) #electron abundance [-]\n",
    "        pipe_cell_elab_part=data['ElectronAbundance'][inidx] #electron abundance [-]\n",
    "\n",
    "        #pipe_cell_sfr_part.append(data['StarFormationRate'][inidx]) #star formation rate [Msun/yr]\n",
    "        pipe_cell_sfr_part=data['StarFormationRate'][inidx] #star formation rate [Msun/yr]\n",
    "\n",
    "        #pipe_cell_dark_part.append(data['SubfindDMDensity'][inidx])  #comoving dark matter density [(1e10Msun/h)/(ckpc/h)**3]\n",
    "        pipe_cell_dark_part=data['SubfindDMDensity'][inidx]  #comoving dark matter density [(1e10Msun/h)/(ckpc/h)**3]\n",
    "\n",
    "        #pipe_cell_warm_part.append(data['Warm'][inidx])\n",
    "        pipe_cell_warm_part=data['Warm'][inidx]\n",
    "\n",
    "        #pipe_cell_pIDs_part.append(data['ParticleIDs'][inidx])\n",
    "        pipe_cell_pIDs_part=data['ParticleIDs'][inidx]\n",
    "        \n",
    "        #########################################\n",
    "        #store these to a dictionary to be saved#\n",
    "        #########################################\n",
    "        \n",
    "        temp_dict['Coordinates']       = pipe_cell_coords_part\n",
    "        temp_dict['Density']           = pipe_cell_dens_part\n",
    "        temp_dict['ElectronAbundance'] = pipe_cell_elab_part\n",
    "        temp_dict['StarFormationRate'] = pipe_cell_sfr_part\n",
    "        temp_dict['SubfindDMdensity']  = pipe_cell_dark_part\n",
    "        temp_dict['Warm']              = pipe_cell_warm_part\n",
    "        temp_dict['ParticleIDs']       = pipe_cell_pIDs_part\n",
    "        \n",
    "        if verbose == True:\n",
    "            print('Verbose mode check: temp dict = {0}'.format(temp_dict))\n",
    "\n",
    "        #####################################################################\n",
    "        #save data to temporary array for loading with the rest of the parts#\n",
    "        #####################################################################\n",
    "        np.save('{0}'.format(part_outdata_filename),temp_dict)\n",
    "\n",
    "        if verbose == True:\n",
    "            print('Verbose mode check: saved')\n",
    "    \n",
    "    \n",
    "    return\n",
    "\n",
    "def unwrap_package(package):\n",
    "    \"\"\"\n",
    "    Helper function for parsing simulation in parallel using multiprocessing.\n",
    "    Unpacks the set of data necessary for parsing the simulation.\n",
    "    Then parses the simulation using process_sim_chunk().\n",
    "    \n",
    "    INPUTS:\n",
    "    \n",
    "    package : a list containing the input data, which are X arguments in the following order:\n",
    "    \n",
    "        snap_number : [int] the snapshot number of the simulation to be processed\n",
    "        basePath    : [str] the path to the simulation data to be processed\n",
    "        sim_to_use  : [str] the simulation to be processed\n",
    "        nSubLoads   : [int] the total number of parts the simulation will be split into\n",
    "        chunkIDs    : [array of ints] the id numbers of the chunks of simulation to be processed on this cpu\n",
    "        T_h         : [= 10**7]  hot phase gase temperature [Kelvin] \n",
    "        T_c         : [= 10**3]  cold phase gas temperature [Kelvin]\n",
    "        c1s         : [0,pipe_width/2,pipe_width/2] coordinates at upper right of pipe start\n",
    "        c2e         : [0,-pipe_width/2,-pipe_width/2] coordinates at lower left of pipe end\n",
    "    \n",
    "    \n",
    "    RETURNS:\n",
    "    \n",
    "    output of process_package()\n",
    "    \"\"\"\n",
    "    \n",
    "    verbose=False\n",
    "    \n",
    "    #unwrap the package to feed to process_sim_chunk()\n",
    "    snap_number = package[0]\n",
    "    if verbose==True:\n",
    "        print('Verbose mode check: snap_number = {0}'.format(snap_number))\n",
    "    basePath    = package[1]\n",
    "    if verbose==True:\n",
    "        print('Verbose mode check: basePath = {0}'.format(basePath))\n",
    "    sim_to_use  = package[2]\n",
    "    if verbose==True:\n",
    "        print('Verbose mode check: sim_to_use = {0}'.format(sim_to_use))\n",
    "    nSubLoads   = package[3]\n",
    "    if verbose==True:\n",
    "        print('Verbose mode check: nSubLoads = {0}'.format(nSubLoads))\n",
    "    chunkIDs    = package[4]\n",
    "    if verbose==True:\n",
    "        print('Verbose mode check: chunkIDs = {0}'.format(chunkIDs))\n",
    "    T_h         = package[5]\n",
    "    if verbose==True:\n",
    "        print('Verbose mode check: T_h = {0}'.format(T_h))\n",
    "    T_c         = package[6]\n",
    "    if verbose==True:\n",
    "        print('Verbose mode check: T_c = {0}'.format(T_c))\n",
    "    c1s         = package[7]\n",
    "    if verbose==True:\n",
    "        print('Verbose mode check: c1s = {0}'.format(c1s))\n",
    "    c2e         = package[8]\n",
    "    if verbose==True:\n",
    "        print('Verbose mode check: c2e = {0}'.format(c2e))\n",
    "    \n",
    "    print('torun: ',snap_number,basePath,sim_to_use,nSubLoads,chunkIDs,T_h,T_c,c1s,c2e)\n",
    "    \n",
    "    \n",
    "    #run process_sim_chunk()\n",
    "    process_sim_chunk(snap_number,basePath,sim_to_use,nSubLoads,chunkIDs,T_h,T_c,c1s,c2e)\n",
    "    \n",
    "    return 'done'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32440b55",
   "metadata": {},
   "source": [
    "# Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1b85d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation to use will be: TNG50-4\n",
      "Number of pipes to create per snapshot: 5126\n",
      "Snapshots to process will be [99]\n",
      "Pipe width will be 200 ckpc/h\n",
      "There will be 10000 bins on each sightline\n",
      "Proton mass is 1.67262192369e-27 kg\n",
      "Chosen H mass fraction is 0.75. Check whether this is correct\n",
      "Critical density at z=0 = 8.619160453152573e-27 kg / m3\n",
      "To parse simulation data, 1 cpus will load data simultaneously. This will happen 100 times. The remaining data needs 0 cpus. These will be loaded simultaneously.\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "#initialise#\n",
    "############\n",
    "\n",
    "sim_to_use = sim_to_use\n",
    "print('Simulation to use will be: {0}'.format(sim_to_use))\n",
    "\n",
    "pipes_per_snap = pipes_per_snap\n",
    "print('Number of pipes to create per snapshot: {0}'.format(pipes_per_snap))\n",
    "\n",
    "snaps_to_process = [snap_to_process]#,13,11,8,6,4,3,2]\n",
    "print('Snapshots to process will be {0}'.format(snaps_to_process))\n",
    "\n",
    "#The number of cells in the chosen snapshot\n",
    "#ncells = dataPT0['Coordinates'].shape[0]\n",
    "#print('Number of cells in snapshot {0} is {1}'.format(snap_number,ncells))\n",
    "\n",
    "#The width of the pipe\n",
    "pipe_width = 200 #By following zhang+20 definition, sides will be 200ckpc/h in length\n",
    "print('Pipe width will be {0} ckpc/h'.format(pipe_width))\n",
    "\n",
    "#The number of bins along a single line of sight\n",
    "nbins=10000 #Zhang+20 definition: 10,000\n",
    "print('There will be {0} bins on each sightline'.format(nbins))\n",
    "\n",
    "#Define the mass of a proton for dDM/dz calculations\n",
    "protonmass = c.m_p.to('kg')\n",
    "print('Proton mass is {0}'.format(protonmass))\n",
    "\n",
    "#Define the hydrogen mass fraction for dDM/dz calculations\n",
    "hmassfrac = 3./4.\n",
    "print('Chosen H mass fraction is {0}. Check whether this is correct'.format(hmassfrac))\n",
    "\n",
    "#calculate the critical density at redshift zero for structure categorisation\n",
    "#source to formula: https://astronomy.swin.edu.au/cosmos/c/Critical+Density\n",
    "grav=c.G.to('m**3/(kg*s**2)') #g as a YT quantity in correct units\n",
    "H=cosmosource.H(0).to('km/s/Mpc') #hubble const at z=0 in km/s/Mpc\n",
    "my_dens_crit = ((3 * H**2)/(8*np.pi* grav)).to('kg/m**3')\n",
    "print('Critical density at z=0 = {0}'.format(my_dens_crit))\n",
    "\n",
    "nSubLoads = 100 #number of subloads to split simulation into\n",
    "\n",
    "##pipe info for test\n",
    "#npipes      = 1  #number of pipes to create\n",
    "#snap_number = 99 #snapshot number for test\n",
    "\n",
    "\n",
    "#base path to simulation\n",
    "#basePath = '/virgo/simulations/IllustrisTNG/{0}/output/'.format(sim_to_use)\n",
    "basePath = '/ptmp/cwalker/Illustris_FRB_Project/TNG_copies/virgo/simulations/IllustrisTNG/{0}/output/'.format(sim_to_use)\n",
    "#basePath = '/virgo/simulations/IllustrisTNG/{0}/output/'.format(sim_to_use)\n",
    "\n",
    "#load header\n",
    "header = il.groupcat.loadHeader(basePath,snap_number)\n",
    "\n",
    "#fields to load for test\n",
    "fields=['Density',\n",
    "        'ElectronAbundance',\n",
    "        'StarFormationRate',\n",
    "        'InternalEnergy',\n",
    "        'Coordinates',\n",
    "        'Masses',\n",
    "        'SubfindDMDensity',\n",
    "        'ParticleIDs'] \n",
    "\n",
    "#define constants foor warm-phase gas mass fraction calculation\n",
    "T_h = 10**7  #hot phase gase temperature [Kelvin]\n",
    "T_c = 10**3  #cold phase gas temperature [Kelvin]\n",
    "x_h = 0.75   #Hydrogen mass fraction\n",
    "\n",
    "#identify number of available cores on the system\n",
    "ncpus = m.cpu_count()\n",
    "\n",
    "#choose the number of cores to use at once. \n",
    "cpus_to_use = cpus_to_use \n",
    "\n",
    "#calculate the number of full core runs to be used to check for simulation cells in pipe\n",
    "#this number is the number of parts of the simulation which will be loaded simultaneously\n",
    "n_full_core = nSubLoads//cpus_to_use\n",
    "\n",
    "#calculate the number of cores which must be used to check the remaining simulation cells\n",
    "#this number is the number of leftover parts of the simulation which will be loaded all at once\n",
    "n_partial_core = nSubLoads%cpus_to_use\n",
    "\n",
    "print('To parse simulation data, {0} cpus will load data simultaneously. This will happen {1} times. The remaining data needs {2} cpus. These will be loaded simultaneously.'.format(cpus_to_use,n_full_core,n_partial_core))\n",
    "\n",
    "#if statement to allow testing of whether multiproccessing-related functions are working correctly\n",
    "#If it is set to False, multiprocessing is enabled.\n",
    "#If set to true, everything is done sequentially with no multiprocessing.\n",
    "parallelcodetest = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc0b28d",
   "metadata": {},
   "source": [
    "# Pipe Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "41dac738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oldpIDshIDconverter(pipe_cell_pIDs,AllPartIDs,AllSubhIDs):\n",
    "    \"\"\"\n",
    "    Old version of the code which took a set of particle IDs and created a list of \n",
    "    corresponding subhalo IDs\n",
    "    \n",
    "    INPUTS:\n",
    "    \n",
    "    pipe_cell_pIDs : the particle ids of cells in a given pipe\n",
    "    AllPartIDs     : particle ID list for all cells in the desired simulation\n",
    "    AllSubhIDs     : subhalo ID list for all cells in the desired simulation\n",
    "    \n",
    "    RETURNS:\n",
    "    \n",
    "    pipe_cell_shIDs : the corresponding subhalo IDs for every particle id in the cell.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #print('Conversion check')\n",
    "\n",
    "    #create a set of particle IDs for the cells in this pipe\n",
    "    PartID_Set = set(pipe_cell_pIDs.tolist())\n",
    "\n",
    "    #initialise an array to contain the corresponding positions within the simulation of these cells\n",
    "    sim_inds = np.zeros(pipe_cell_pIDs.shape,dtype=int)\n",
    "\n",
    "    #loop over all particle IDs in the desired simulation\n",
    "    for i, x in enumerate(AllPartIDs):\n",
    "\n",
    "        #find when particle ID is also in the pipe\n",
    "        if x in PartID_Set:\n",
    "\n",
    "            #find where that particle ID is in the pipe\n",
    "            pipe_idx = np.where(pipe_cell_pIDs==x)\n",
    "\n",
    "            #assign the pipe at that point the cell's corresponding simulation position\n",
    "            sim_inds[pipe_idx] = i\n",
    "\n",
    "\n",
    "    #for all of these simulation positions, get the correct subhalo ID\n",
    "    pipe_cell_shIDs = np.array(AllSubhIDs[sim_inds])\n",
    "    #print(pipe_cell_shIDs)\n",
    "\n",
    "    #print('Conversion check end')\n",
    "\n",
    "    return pipe_cell_shIDs\n",
    "\n",
    "def newpIDshIDconverter(pipe_cell_pIDs,ChunkedPartIDs,ChunkedSubhIDs):\n",
    "    \"\"\"\n",
    "    New version of the code which creates a set of subhalo IDs from a set of particle\n",
    "    IDs.\n",
    "    \n",
    "    This version loops through each chunk of the simulation ID lists in turn searching\n",
    "    for relevant particle and subhalo IDs. \n",
    "    \n",
    "    Note: could be improved to be faster if, when all correct particle IDs are found, it\n",
    "    does not need to search further chunks. This is not yet implemented.\n",
    "    \n",
    "    INPUTS:\n",
    "    \n",
    "    pipe_cell_pIDs : the particle ids of cells in a given pipe\n",
    "    ChunkedPartIDs : list containing locations of the chunks of \n",
    "                     the particle ID list for all cells in the \n",
    "                     desired simulation. If all of these were loaded\n",
    "                     into a single array, the result would be the\n",
    "                     same as AllPartIDs in oldpIDshIDconverter().\n",
    "    ChunkedSubhIDs : list containing locations of the chunks of \n",
    "                     the subhalo ID list for all cells in the \n",
    "                     desired simulation. If all of these were loaded\n",
    "                     into a single array, the result would be the\n",
    "                     same as AllPartIDs in oldpIDshIDconverter().\n",
    "    \n",
    "    RETURNS:\n",
    "    \n",
    "    pipe_cell_shIDs : the corresponding subhalo IDs for every particle id in the cell.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #create a set of particle IDs for the cells in this pipe\n",
    "    PartID_Set = set(pipe_cell_pIDs.tolist())\n",
    "    \n",
    "    #initialise an array to contain all subhalo IDs in simulation\n",
    "    pipe_cell_shIDs = np.ones(pipe_cell_pIDs.shape,dtype=int)*-1\n",
    "    \n",
    "    #print(ChunkedPartIDs)\n",
    "    \n",
    "    #load chunks of the all-simulation particle ID list\n",
    "    for i in range(len(ChunkedPartIDs)):\n",
    "        \n",
    "        #True/False array of same shape as pipe data which allows \n",
    "        #us to extract the relevant IDs from each chunk\n",
    "        TF_arr = np.full(pipe_cell_pIDs.shape, False) #begin with false, flip to true when chunk contains ID\n",
    "        \n",
    "        sim_inds = []#initialise an array to contain  positions of any cells in this chunk\n",
    "        \n",
    "        #get location of chunks to load\n",
    "        PartFile_toload = ChunkedPartIDs[i] #all-simulation particle ID list chunk\n",
    "        SubhFile_toload = ChunkedSubhIDs[i] #all-simulation subhalo ID list chunk\n",
    "        \n",
    "        #load the ID list chunks\n",
    "        ChunkOfPartIDs = np.load(PartFile_toload) #particle chunk\n",
    "        ChunkOfSubhIDs = np.load(SubhFile_toload) #subhalo chunk\n",
    "\n",
    "        #loop over the particle IDs in the chunk\n",
    "        for j, x in enumerate(ChunkOfPartIDs):\n",
    "            \n",
    "            #find if particle ID is also in the pipe\n",
    "            if x in PartID_Set:\n",
    "                                \n",
    "                #find where that particle ID is in the pipe\n",
    "                pipe_idx = np.where(pipe_cell_pIDs==x)\n",
    "                \n",
    "                #flip the True/False array index to True for this cell\n",
    "                TF_arr[pipe_idx] = True\n",
    "                \n",
    "                #append the cell's corresponding chunk position\n",
    "                sim_inds.append(j)\n",
    "                \n",
    "                #print(i,j,pipe_idx,x,ChunkOfSubhIDs[j])\n",
    "\n",
    "            \n",
    "        #convert all chunk position indices to array\n",
    "        sim_inds = np.array(sim_inds)\n",
    "        \n",
    "        #record all corresponding subhalo IDs in this chunk\n",
    "        #print(pipe_cell_shIDs[TF_arr])\n",
    "        #print(sim_inds)\n",
    "        #print(ChunkOfSubhIDs[sim_inds])\n",
    "        if sim_inds.size>0:#only try this if the array is not empty\n",
    "            pipe_cell_shIDs[TF_arr] = ChunkOfSubhIDs[sim_inds]\n",
    "            \n",
    "\n",
    "    return pipe_cell_shIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "29d34860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing snapshot: 99\n",
      "Header for snap = {'BoxSize': 35000.0, 'FlagDoubleprecision': 0, 'Git_commit': b'unknown', 'Git_date': b'unknown', 'HubbleParam': 0.6774, 'Ngroups_ThisFile': 2, 'Ngroups_Total': 25257, 'Nids_ThisFile': 1340081, 'Nids_Total': 15550740, 'Nsubgroups_ThisFile': 503, 'Nsubgroups_Total': 22869, 'NumFiles': 11, 'Omega0': 0.3089, 'OmegaLambda': 0.6911, 'Redshift': 2.220446049250313e-16, 'Time': 0.9999999999999998}\n",
      "Using new version of code which loads particle/subhalo matchlists in chunks from /ptmp/\n",
      "Note: File /u/cwalker/Illustris_Zhang_Method/Sim_TNG50-4_Snap_99_dDMdz_Output_pID_test.npy already exists. Will be loaded.\n",
      "Loading file (/u/cwalker/Illustris_Zhang_Method/Sim_TNG50-4_Snap_99_dDMdz_Output_pID_test.npy)\n",
      "File loaded has 17 keys\n",
      "Warning: File currently contains too few pipes (5125/5126)\n",
      "Remaining number of pipes needed is: 1\n",
      "Running parallelised version to check parallelisation\n",
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      "  48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      "  72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      "  96 97 98 99]]\n",
      "torun:  99 /ptmp/cwalker/Illustris_FRB_Project/TNG_copies/virgo/simulations/IllustrisTNG/TNG50-4/output/ TNG50-4 100 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99] 10000000 1000 [    0.         17981.18504878 18211.08915536] [35000.         17781.18504878 18011.08915536]\n",
      "new shID code\n",
      "Running parallelised version to check parallelisation\n",
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      "  48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      "  72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      "  96 97 98 99]]\n",
      "torun:  99 /ptmp/cwalker/Illustris_FRB_Project/TNG_copies/virgo/simulations/IllustrisTNG/TNG50-4/output/ TNG50-4 100 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99] 10000000 1000 [    0.         13719.58096841 30297.84835455] [35000.         13519.58096841 30097.84835455]\n",
      "new shID code\n",
      "Running parallelised version to check parallelisation\n",
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      "  48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      "  72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      "  96 97 98 99]]\n",
      "torun:  99 /ptmp/cwalker/Illustris_FRB_Project/TNG_copies/virgo/simulations/IllustrisTNG/TNG50-4/output/ TNG50-4 100 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99] 10000000 1000 [    0.         33527.72276471 23007.81776003] [35000.         33327.72276471 22807.81776003]\n",
      "new shID code\n",
      "Running parallelised version to check parallelisation\n",
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      "  48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      "  72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      "  96 97 98 99]]\n",
      "torun:  99 /ptmp/cwalker/Illustris_FRB_Project/TNG_copies/virgo/simulations/IllustrisTNG/TNG50-4/output/ TNG50-4 100 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99] 10000000 1000 [    0.          2405.44030567 29279.48993795] [35000.          2205.44030567 29079.48993795]\n",
      "new shID code\n",
      "Running parallelised version to check parallelisation\n",
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      "  48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      "  72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      "  96 97 98 99]]\n",
      "torun:  99 /ptmp/cwalker/Illustris_FRB_Project/TNG_copies/virgo/simulations/IllustrisTNG/TNG50-4/output/ TNG50-4 100 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99] 10000000 1000 [    0.          4984.81326838 19949.57175981] [35000.          4784.81326838 19749.57175981]\n",
      "new shID code\n",
      "Running parallelised version to check parallelisation\n",
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      "  48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      "  72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      "  96 97 98 99]]\n",
      "torun:  99 /ptmp/cwalker/Illustris_FRB_Project/TNG_copies/virgo/simulations/IllustrisTNG/TNG50-4/output/ TNG50-4 100 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99] 10000000 1000 [    0.         30848.92818766   511.84247621] [35000.         30648.92818766   311.84247621]\n",
      "new shID code\n",
      "Running parallelised version to check parallelisation\n",
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      "  48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      "  72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      "  96 97 98 99]]\n",
      "torun:  99 /ptmp/cwalker/Illustris_FRB_Project/TNG_copies/virgo/simulations/IllustrisTNG/TNG50-4/output/ TNG50-4 100 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99] 10000000 1000 [    0.           468.94707959 26968.56665089] [35000.           268.94707959 26768.56665089]\n",
      "new shID code\n",
      "Running parallelised version to check parallelisation\n",
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      "  48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      "  72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      "  96 97 98 99]]\n",
      "torun:  99 /ptmp/cwalker/Illustris_FRB_Project/TNG_copies/virgo/simulations/IllustrisTNG/TNG50-4/output/ TNG50-4 100 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99] 10000000 1000 [    0.         10791.03521009 22966.89568975] [35000.         10591.03521009 22766.89568975]\n",
      "new shID code\n",
      "Running parallelised version to check parallelisation\n",
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      "  48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      "  72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      "  96 97 98 99]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torun:  99 /ptmp/cwalker/Illustris_FRB_Project/TNG_copies/virgo/simulations/IllustrisTNG/TNG50-4/output/ TNG50-4 100 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99] 10000000 1000 [    0.          1075.61193679 16563.18445778] [35000.           875.61193679 16363.18445778]\n",
      "new shID code\n",
      "Running parallelised version to check parallelisation\n",
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      "  48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      "  72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      "  96 97 98 99]]\n",
      "torun:  99 /ptmp/cwalker/Illustris_FRB_Project/TNG_copies/virgo/simulations/IllustrisTNG/TNG50-4/output/ TNG50-4 100 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99] 10000000 1000 [    0.         26348.50372644 19399.63558317] [35000.         26148.50372644 19199.63558317]\n",
      "new shID code\n",
      "Running parallelised version to check parallelisation\n",
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      "  48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      "  72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      "  96 97 98 99]]\n",
      "torun:  99 /ptmp/cwalker/Illustris_FRB_Project/TNG_copies/virgo/simulations/IllustrisTNG/TNG50-4/output/ TNG50-4 100 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99] 10000000 1000 [    0.         24849.58261542 11350.98853584] [35000.         24649.58261542 11150.98853584]\n",
      "new shID code\n",
      "Running parallelised version to check parallelisation\n",
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      "  48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      "  72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      "  96 97 98 99]]\n",
      "torun:  99 /ptmp/cwalker/Illustris_FRB_Project/TNG_copies/virgo/simulations/IllustrisTNG/TNG50-4/output/ TNG50-4 100 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99] 10000000 1000 [    0.         29753.46229957  1192.2598086 ] [35000.         29553.46229957   992.2598086 ]\n",
      "new shID code\n",
      "Running parallelised version to check parallelisation\n",
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      "  48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      "  72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      "  96 97 98 99]]\n",
      "torun:  99 /ptmp/cwalker/Illustris_FRB_Project/TNG_copies/virgo/simulations/IllustrisTNG/TNG50-4/output/ TNG50-4 100 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99] 10000000 1000 [    0.         28618.77463405  3680.01763061] [35000.         28418.77463405  3480.01763061]\n",
      "new shID code\n",
      "Running parallelised version to check parallelisation\n",
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      "  48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      "  72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      "  96 97 98 99]]\n",
      "torun:  99 /ptmp/cwalker/Illustris_FRB_Project/TNG_copies/virgo/simulations/IllustrisTNG/TNG50-4/output/ TNG50-4 100 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99] 10000000 1000 [    0.         14745.50564976  4677.05977621] [35000.         14545.50564976  4477.05977621]\n",
      "new shID code\n",
      "Running parallelised version to check parallelisation\n",
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      "  48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      "  72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      "  96 97 98 99]]\n",
      "torun:  99 /ptmp/cwalker/Illustris_FRB_Project/TNG_copies/virgo/simulations/IllustrisTNG/TNG50-4/output/ TNG50-4 100 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99] 10000000 1000 [    0.          4107.44350545 11195.38664556] [35000.          3907.44350545 10995.38664556]\n",
      "new shID code\n",
      "Running parallelised version to check parallelisation\n",
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      "  48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      "  72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      "  96 97 98 99]]\n",
      "torun:  99 /ptmp/cwalker/Illustris_FRB_Project/TNG_copies/virgo/simulations/IllustrisTNG/TNG50-4/output/ TNG50-4 100 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99] 10000000 1000 [    0.         27647.23128719 24805.01344045] [35000.         27447.23128719 24605.01344045]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-99:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_109870/3968208598.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpus_to_use\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#invoke multiproccessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                         \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munwrap_package\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#run the multiprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#terminate after completion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_15/packages/x86_64/anaconda/3/2020.02/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_15/packages/x86_64/anaconda/3/2020.02/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_15/packages/x86_64/anaconda/3/2020.02/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_15/packages/x86_64/anaconda/3/2020.02/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_15/packages/x86_64/anaconda/3/2020.02/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/mpcdf/soft/SLE_15/packages/x86_64/anaconda/3/2020.02/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/mpcdf/soft/SLE_15/packages/x86_64/anaconda/3/2020.02/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mpcdf/soft/SLE_15/packages/x86_64/anaconda/3/2020.02/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/mpcdf/soft/SLE_15/packages/x86_64/anaconda/3/2020.02/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/tmp/ipykernel_109870/4185591440.py\", line 314, in unwrap_package\n",
      "    process_sim_chunk(snap_number,basePath,sim_to_use,nSubLoads,chunkIDs,T_h,T_c,c1s,c2e)\n",
      "  File \"/tmp/ipykernel_109870/4185591440.py\", line 167, in process_sim_chunk\n",
      "    data = loadSubset(basePath,snap_number, 'gas', fields,chunkNum=chunkID, totNumChunks=nSubLoads)\n",
      "  File \"/tmp/ipykernel_109870/4185591440.py\", line 107, in loadSubset\n",
      "    r = il.snapshot.loadSubset(simPath, snap, partType, fields, subset=subset)\n",
      "  File \"/u/cwalker/git_python_downloads/illustris_python/snapshot.py\", line 132, in loadSubset\n",
      "    result[field][wOffset:wOffset+numToReadLocal] = f[gName][field][fileOff:fileOff+numToReadLocal]\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"/mpcdf/soft/SLE_15/packages/x86_64/anaconda/3/2020.02/lib/python3.7/site-packages/h5py/_hl/dataset.py\", line 573, in __getitem__\n",
      "    self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "########################\n",
    "##ACTUAL PIPE CREATION##\n",
    "########################\n",
    "########################\n",
    "\n",
    "pIDshID_version = 'new' #a switch while testing the new vs old shID versions, can be old, new, both\n",
    "\n",
    "\n",
    "#####################\n",
    "#Loop over snapshots#\n",
    "#####################\n",
    "\n",
    "for snapshot_to_process in range(len(snaps_to_process)):\n",
    "   \n",
    "    ############\n",
    "    #initialise#\n",
    "    ############\n",
    "    \n",
    "    npipes            = pipes_per_snap  #number of pipes to create\n",
    "    snap_number       = snaps_to_process[snapshot_to_process] #snapshot number for test\n",
    "    \n",
    "    print('Currently processing snapshot: {0}'.format(snap_number))\n",
    "    \n",
    "    \n",
    "    #############\n",
    "    #load header#\n",
    "    #############\n",
    "    \n",
    "    header = il.groupcat.loadHeader(basePath,snap_number)\n",
    "    print('Header for snap = {0}'.format(header))\n",
    "    \n",
    "    #####################################################################################################\n",
    "    #edit for larger simulations: put this in an if statement to test both chunkeed and whole matchlists#\n",
    "    #####################################################################################################\n",
    "    \n",
    "    #load the particle and subhalo ID lists for all cells in the desired simulation\n",
    "    if pIDshID_version == 'old':\n",
    "        #load the whole matchlists\n",
    "        AllPartIDs = np.load('/u/cwalker/Illustris_Zhang_Method/Sim_Matchlists/Matchlist_dir_{0}/PartList_Snap{1}.npy'.format(sim_to_use,snap_number))\n",
    "        AllSubhIDs = np.load('/u/cwalker/Illustris_Zhang_Method/Sim_Matchlists/Matchlist_dir_{0}/ShIDList_Snap{1}.npy'.format(sim_to_use,snap_number))\n",
    "    \n",
    "    elif pIDshID_version == 'new':\n",
    "        #get list of matchlist chunks\n",
    "        print('Using new version of code which loads particle/subhalo matchlists in chunks from /ptmp/')\n",
    "        Chunked_loc = '/ptmp/cwalker/Illustris_FRB_Project/Sim_Matchlists/Matchlist_dir_{0}/'.format(sim_to_use) #location of the chunked data\n",
    "        \n",
    "        #get the particle ID list chunks\n",
    "        ChunkedPartIDs = os.listdir(Chunked_loc)\n",
    "        ChunkedPartIDs = ['{0}/{1}'.format(Chunked_loc,i) for i in ChunkedPartIDs if 'PartList_Snap{0}_Chunk'.format(snap_number) in i]\n",
    "        ChunkedPartIDs.sort()\n",
    "        \n",
    "        #get the subhalo ID list chunks\n",
    "        ChunkedSubhIDs = os.listdir(Chunked_loc)\n",
    "        ChunkedSubhIDs = ['{0}/{1}'.format(Chunked_loc,i) for i in ChunkedSubhIDs if 'ShIDList_Snap{0}_Chunk'.format(snap_number) in i]\n",
    "        ChunkedSubhIDs.sort()\n",
    "        \n",
    "    elif pIDshID_version == 'both':\n",
    "        print('Checking output of new and old subhalo ID generation methods...')\n",
    "        #load the whole matchlists\n",
    "        AllPartIDs = np.load('/u/cwalker/Illustris_Zhang_Method/Sim_Matchlists/Matchlist_dir_{0}/PartList_Snap{1}.npy'.format(sim_to_use,snap_number))\n",
    "        AllSubhIDs = np.load('/u/cwalker/Illustris_Zhang_Method/Sim_Matchlists/Matchlist_dir_{0}/ShIDList_Snap{1}.npy'.format(sim_to_use,snap_number))        \n",
    "\n",
    "        #get list of matchlist chunks\n",
    "        Chunked_loc = '/ptmp/cwalker/Illustris_FRB_Project/Sim_Matchlists/Matchlist_dir_{0}/'.format(sim_to_use) #location of the chunked data\n",
    "        print('Location of Particle ID matchlist chunks: {0}'.format(Chunked_loc))\n",
    "        \n",
    "        #get the particle ID list chunks\n",
    "        ChunkedPartIDs = os.listdir(Chunked_loc)\n",
    "        #print('All files in the location: {0}'.format(ChunkedPartIDs))\n",
    "        print('Testing for string: {0}'.format('PartList_Snap{0}_Chunk'.format(snap_number)))\n",
    "        #print([i for i in ChunkedPartIDs if 'PartList_Snap{0}_Chunk'.format(snap_number) in i])\n",
    "        ChunkedPartIDs = ['{0}/{1}'.format(Chunked_loc,i) for i in ChunkedPartIDs if 'PartList_Snap{0}_Chunk'.format(snap_number) in i]\n",
    "        ChunkedPartIDs.sort()\n",
    "        #print('Particle ID matchlist chunks: {0}'.format(ChunkedPartIDs))\n",
    "        \n",
    "        #get the subhalo ID list chunks\n",
    "        ChunkedSubhIDs = os.listdir(Chunked_loc)\n",
    "        ChunkedSubhIDs = ['{0}/{1}'.format(Chunked_loc,i) for i in ChunkedSubhIDs if 'ShIDList_Snap{0}_Chunk'.format(snap_number) in i]\n",
    "        ChunkedSubhIDs.sort()\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "    #######################################################\n",
    "    #######################################################\n",
    "    ##Check that file to store data dictionary in exists.##\n",
    "    ##If it doesn't, create it and initialise it.        ##\n",
    "    ##If it does, load it.                               ##\n",
    "    #######################################################\n",
    "    #######################################################\n",
    "    \n",
    "    #outfile_name = '/u/cwalker/Illustris_Zhang_Method/Sim_{0}_Snap_{1}_dDMdz_Output.npy'.format(sim_to_use,snap_number) #name of this file\n",
    "    outfile_name = '/u/cwalker/Illustris_Zhang_Method/Sim_{0}_Snap_{1}_dDMdz_Output_pID_test.npy'.format(sim_to_use,snap_number) #name of this file\n",
    "\n",
    "     \n",
    "    #####################################\n",
    "    #check to see if file already exists#\n",
    "    #####################################\n",
    "        \n",
    "    if not os.path.isfile('{0}'.format(outfile_name)):\n",
    "        print('Warning: file {0} does not yet exist. Must be created.'.format(outfile_name))\n",
    "        existcheck = False\n",
    "    else:\n",
    "        print('Note: File {0} already exists. Will be loaded.'.format(outfile_name))\n",
    "        existcheck = True\n",
    "        \n",
    "    ######################\n",
    "    #if file exists, load#\n",
    "    ######################\n",
    "    if existcheck == True:\n",
    "        print('Loading file ({0})'.format(outfile_name))\n",
    "        dict_to_edit = np.load(outfile_name,allow_pickle=True).tolist()\n",
    "        print('File loaded has {0} keys'.format(len(dict_to_edit)))\n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    #if file doesn't exist, create and initialise#\n",
    "    ##############################################\n",
    "    \n",
    "    if existcheck == False:\n",
    "        print('Creating file ({0})'.format(outfile_name))\n",
    "        dict_to_edit = {} # initialise\n",
    "        \n",
    "        #initialise keys to be stored\n",
    "        dict_to_edit['dDMdz_Zhang'] = []\n",
    "        dict_to_edit['dDMdzHalo_Zhang'] = []\n",
    "        dict_to_edit['dDMdzFilament_Zhang'] = []\n",
    "        dict_to_edit['dDMdzVoid_Zhang'] = []\n",
    "        dict_to_edit['nHalo_Zhang'] = []\n",
    "        dict_to_edit['nFilament_Zhang'] = []\n",
    "        dict_to_edit['nVoid_Zhang'] = []\n",
    "\n",
    "        dict_to_edit['dDMdz_Pakmor'] = []\n",
    "        dict_to_edit['dDMdzHalo_Pakmor'] = []\n",
    "        dict_to_edit['dDMdzFilament_Pakmor'] = []\n",
    "        dict_to_edit['dDMdzVoid_Pakmor'] = []\n",
    "        dict_to_edit['nHalo_Pakmor'] = []\n",
    "        dict_to_edit['nFilament_Pakmor'] = []\n",
    "        dict_to_edit['nVoid_Pakmor'] = []\n",
    "        \n",
    "        #edit 09/02/22 for storing information about subhalos along sightline\n",
    "        dict_to_edit['firstShID'] = [] #first subhalo ID number along pipe line of sight\n",
    "        dict_to_edit['uniqueShIDs'] = [] #unique subhalo ID numbers along pipe line of sight\n",
    "        dict_to_edit['closestCoords'] = [] #closest coordinates along pipe line of sight to these subhalos\n",
    "        \n",
    "        #save\n",
    "        np.save('{0}'.format(outfile_name),dict_to_edit)\n",
    "        print('File created and initialised')\n",
    "        \n",
    "        \n",
    "    #######################################################\n",
    "    #check to see if file contains correct number of pipes#\n",
    "    #######################################################\n",
    "    \n",
    "    if len(dict_to_edit['dDMdz_Pakmor'])<npipes:\n",
    "        print('Warning: File currently contains too few pipes ({0}/{1})'.format(len(dict_to_edit['dDMdz_Pakmor']),npipes))\n",
    "        lencheck = False\n",
    "    \n",
    "    elif len(dict_to_edit['dDMdz_Pakmor'])==npipes:\n",
    "        print('Warning: File already contains the correct number of pipes ({0}). No more will be created'.format(len(dict_to_edit['dDMdz_Pakmor'])))\n",
    "        lencheck = True\n",
    "    \n",
    "    ###################################################################\n",
    "    #if number of pipes is too low, calculate how many more are needed#\n",
    "    ###################################################################\n",
    "    \n",
    "    if lencheck == False:\n",
    "        new_npipes = npipes - len(dict_to_edit['dDMdz_Pakmor'])\n",
    "        print('Remaining number of pipes needed is: {0}'.format(new_npipes))\n",
    "    \n",
    "    #####################################\n",
    "    #if number of pipes is correct, exit#\n",
    "    #####################################\n",
    "    \n",
    "    if lencheck == True:\n",
    "        print('No new pipes needed. Quitting program.')\n",
    "        #break\n",
    "\n",
    "    \n",
    "    ###########################\n",
    "    ###########################\n",
    "    ##create pipes, get dDMdz##\n",
    "    ###########################\n",
    "    ###########################\n",
    "    elif lencheck==False:\n",
    "        while(len(dict_to_edit['dDMdz_Pakmor'])<npipes): #while not enough pipes have been created:\n",
    "\n",
    "            #############\n",
    "            #Create Pipe#\n",
    "            #############\n",
    "\n",
    "            #HACK FOR TESTING TO MAKEE SURE IT ONLY LOOPS ONCE. REMOVE BEFORRE PUTTING IN SCRIPT!\n",
    "            #npipes = 0\n",
    "\n",
    "            #########################################\n",
    "            #define los coordinates at start of pipe#\n",
    "            #########################################\n",
    "\n",
    "            #By Zhang+20 definition of following x-axis,\n",
    "            #x will be zero, y and z will be random\n",
    "            #units default = ckpc/h (compare box size to https://www.tng-project.org/about/)\n",
    "\n",
    "            pipe_start_coords = np.array([0,\n",
    "                                 np.random.uniform(0,header['BoxSize'],1)[0],\n",
    "                                 np.random.uniform(0,header['BoxSize'],1)[0]])\n",
    "            #print('Random start cell coordinates: {0}'.format(pipe_start_coords))\n",
    "\n",
    "            ###################################\n",
    "            #define coordinates at end of pipe#\n",
    "            ###################################\n",
    "\n",
    "            #By Zhang+20 definition of following x-axis,\n",
    "            #x will be length of simulation,y and z will be same as start coords\n",
    "\n",
    "            pipe_end_coords = pipe_start_coords+np.array([header['BoxSize'],0,0])\n",
    "            #print('Pipe end cell coordinates: {0}'.format(pipe_end_coords))\n",
    "\n",
    "\n",
    "            ########################\n",
    "            #plot the line of sight#\n",
    "            ########################\n",
    "\n",
    "            los_toplot=list(zip(pipe_start_coords,pipe_end_coords))\n",
    "\n",
    "            ########################\n",
    "            #construct pipe corners#\n",
    "            ########################\n",
    "\n",
    "            #Add and subtract half of pipe length from y and z coords for y and z boundaries\n",
    "            #code adapted from https://stackoverflow.com/questions/33540109/plot-surfaces-on-a-cube\n",
    "\n",
    "            c1s = pipe_start_coords + np.array([0,pipe_width/2,pipe_width/2]) #start corner 1\n",
    "            c2s = pipe_start_coords + np.array([0,-pipe_width/2,-pipe_width/2]) #start corner 2\n",
    "            c3s = pipe_start_coords + np.array([0,pipe_width/2,-pipe_width/2]) #start corner 3\n",
    "            c4s = pipe_start_coords + np.array([0,-pipe_width/2,pipe_width/2]) #start corner 4\n",
    "\n",
    "            c1e = pipe_end_coords + np.array([0,pipe_width/2,pipe_width/2]) #end corner 1\n",
    "            c2e = pipe_end_coords + np.array([0,-pipe_width/2,-pipe_width/2]) #end corner 2\n",
    "            c3e = pipe_end_coords + np.array([0,pipe_width/2,-pipe_width/2]) #end corner 3\n",
    "            c4e = pipe_end_coords + np.array([0,-pipe_width/2,pipe_width/2]) #end corner 4\n",
    "\n",
    "            corners = np.array([c1s,c2s,c3s,c4s,c1e,c2e,c3e,c4e])\n",
    "\n",
    "            ######################\n",
    "            #construct pipe edges#\n",
    "            ######################\n",
    "\n",
    "            line1 = list(zip(c1s,c1e))\n",
    "            line2 = list(zip(c2s,c2e))\n",
    "            line3 = list(zip(c3s,c3e))\n",
    "            line4 = list(zip(c4s,c4e))\n",
    "            line5 = list(zip(c1s,c3s))\n",
    "            line6 = list(zip(c3s,c2s))\n",
    "            line7 = list(zip(c2s,c4s))\n",
    "            line8 = list(zip(c4s,c1s))\n",
    "            line9 = list(zip(c1e,c3e))\n",
    "            line10 = list(zip(c3e,c2e))\n",
    "            line11 = list(zip(c2e,c4e))\n",
    "            line12 = list(zip(c4e,c1e))\n",
    "\n",
    "            lines_todraw = np.array([line1,line2,line3,line4,line5,line6,line7,line8,line9,line10,line11,line12])\n",
    "\n",
    "            ###########################################\n",
    "            #get cells in this pipe by partial loading#\n",
    "            ###########################################\n",
    "\n",
    "            ###########################################\n",
    "            ###########################################\n",
    "            ##Parallelisation edit of the code begins##\n",
    "            ###########################################\n",
    "            ###########################################\n",
    "\n",
    "            \n",
    "            if parallelcodetest == True:\n",
    "                print('Running non parallel version of code to test functions')\n",
    "                \n",
    "            #test  of functions\n",
    "                cpu_map_a = np.arange(n_full_core*cpus_to_use).reshape(cpus_to_use,n_full_core)\n",
    "                cpu_map_b = np.arange(n_full_core*cpus_to_use,nSubLoads).reshape(n_partial_core,1)\n",
    "                package_a = [(snap_number,basePath,sim_to_use,nSubLoads,cpu_map_a[i],T_h,T_c,c1s,c2e) for i in range(cpus_to_use)]\n",
    "                package_b = [(snap_number,basePath,sim_to_use,nSubLoads,cpu_map_b[i],T_h,T_c,c1s,c2e) for i in range(n_partial_core)]\n",
    "                print('Testing CPU maps: A: {0}\\n B: {1}'.format(cpu_map_a,cpu_map_b))\n",
    "                print('Testing packages: A: {0}\\n B: {1}'.format(package_a,package_b))\n",
    "                #running one package through the code\n",
    "                print('Package to run (A): {0}'.format(package_a[0]))\n",
    "                print('Package to run (B): {0}'.format(package_b[0]))\n",
    "                print('\\nrunning A...\\n')\n",
    "                for test_i in range(len(package_a)):\n",
    "                    unwrap_package(package_a[test_i])\n",
    "                print('\\nrunning B...\\n')\n",
    "                for test_i in range(len(package_b)):\n",
    "                    unwrap_package(package_b[test_i])\n",
    "                print('\\nRan successfully')\n",
    "                \n",
    "            elif parallelcodetest==False:\n",
    "                print('Running parallelised version to check parallelisation')\n",
    "            \n",
    "                #create cpu_map and packages for processing\n",
    "                #this array dictates which sections of the data a cpu will load\n",
    "\n",
    "                if n_partial_core ==0: #if there are no remaining parts to load after the full core runs:\n",
    "                    #cpu map\n",
    "                    cpu_map = np.arange(n_full_core*cpus_to_use).reshape(cpus_to_use,n_full_core)\n",
    "                    #the package to be unwrapped for multiprocessing\n",
    "                    package = [(snap_number,basePath,sim_to_use,nSubLoads,cpu_map[i],T_h,T_c,c1s,c2e) for i in range(cpus_to_use)]\n",
    "\n",
    "                    print(cpu_map)\n",
    "\n",
    "                    with closing(Pool(cpus_to_use)) as p: #invoke multiproccessing\n",
    "                        run = p.map(unwrap_package,package,chunksize=1) #run the multiprocessing\n",
    "                    p.terminate() #terminate after completion\n",
    "\n",
    "                elif n_partial_core > 0: #if there are remaining parts to load after the full core runs:\n",
    "                    #cpu map for full core runs\n",
    "                    cpu_map_a = np.arange(n_full_core*cpus_to_use).reshape(cpus_to_use,n_full_core)\n",
    "                    #package for full core runs\n",
    "                    package_a = [(snap_number,basePath,sim_to_use,nSubLoads,cpu_map_a[i],T_h,T_c,c1s,c2e) for i in range(cpus_to_use)]\n",
    "                    #cpu map for partial core run\n",
    "                    cpu_map_b = np.arange(n_full_core*cpus_to_use,nSubLoads).reshape(n_partial_core,1)\n",
    "                    #package for full core runs\n",
    "                    package_b = [(snap_number,basePath,sim_to_use,nSubLoads,cpu_map_b[i],T_h,T_c,c1s,c2e) for i in range(n_partial_core)]\n",
    "\n",
    "                    print('a',cpu_map_a,package_a,'b',cpu_map_b,package_b)\n",
    "\n",
    "                    #full core multiprocessing\n",
    "                    print('full core')\n",
    "                    with closing(Pool(cpus_to_use)) as p: #invoke multiproccessing\n",
    "                        run = p.map(unwrap_package,package_a,chunksize=1) #run the multiprocessing\n",
    "                    p.terminate() #terminate after completion\n",
    "\n",
    "                    #partial core multiprocessing\n",
    "                    print('partial core')\n",
    "                    with closing(Pool(n_partial_core)) as p: #invoke multiproccessing\n",
    "                        run = p.map(unwrap_package,package_b,chunksize=1) #run the multiprocessing\n",
    "                    p.terminate() #terminate after completion\n",
    "            \n",
    "            \n",
    "            ###########################################################\n",
    "            #loop over stored temporary files for each part, load data#\n",
    "            ###########################################################\n",
    "            \n",
    "            #initialise arrays to hold all loaded data\n",
    "\n",
    "            all_coords = [] #coordinates\n",
    "            all_dens  = [] #density\n",
    "            all_elab  = [] #electron abundance\n",
    "            all_sfr   = [] #star formation rate\n",
    "            all_dark  = [] #dark matter density\n",
    "            all_warm  = [] #warm phase gas mass fraction\n",
    "            all_pIDs  = [] #particle ID number\n",
    "            \n",
    "            for i in range(nSubLoads): #loop over parts\n",
    "\n",
    "                #load file\n",
    "                toload_filename = '/u/cwalker/Illustris_Zhang_Method/temp_chunks/sim_{0:02d}_snap_{1:03d}_cID_{2}.npy'.format(snap_number,i,sim_to_use) \n",
    "                loaded_dict = np.load(toload_filename,allow_pickle=True).tolist()\n",
    "\n",
    "                #append data to array\n",
    "                all_coords.append(loaded_dict['Coordinates'])\n",
    "                all_dens.append(loaded_dict['Density'])\n",
    "                all_elab.append(loaded_dict['ElectronAbundance'])\n",
    "                all_sfr.append(loaded_dict['StarFormationRate'])\n",
    "                all_dark.append(loaded_dict['SubfindDMdensity'])\n",
    "                all_warm.append(loaded_dict['Warm'])\n",
    "                all_pIDs.append(loaded_dict['ParticleIDs'])\n",
    "                \n",
    "                #remove temporary file after loading\n",
    "                os.remove(toload_filename)\n",
    "\n",
    "            #############################\n",
    "            #flatten into correct format#\n",
    "            #############################\n",
    "\n",
    "            pipe_cell_coords = np.array([item for sublist in all_coords for item in sublist])\n",
    "            pipe_cell_dens = np.array([item for sublist in all_dens for item in sublist])\n",
    "            pipe_cell_elab = np.array([item for sublist in all_elab for item in sublist])\n",
    "            pipe_cell_sfr = np.array([item for sublist in all_sfr for item in sublist])\n",
    "            pipe_cell_dark = np.array([item for sublist in all_dark for item in sublist])\n",
    "            pipe_cell_warm = np.array([item for sublist in all_warm for item in sublist])\n",
    "            pipe_cell_pIDs = np.array([item for sublist in all_pIDs for item in sublist])\n",
    "            \n",
    "            \n",
    "            ##################################\n",
    "            ##################################\n",
    "            ##parallelisation edit ends here##\n",
    "            ##################################\n",
    "            ##################################\n",
    "\n",
    "            ############################\n",
    "            ############################\n",
    "            ##partial load insert ends##\n",
    "            ############################\n",
    "            ############################\n",
    "            \n",
    "            ############################\n",
    "            ############################\n",
    "            ##subhalo ID insert begins##\n",
    "            ############################\n",
    "            ############################\n",
    "            \n",
    "            #####################################\n",
    "            #Convert particle IDs to subhalo ids#\n",
    "            #####################################\n",
    "            \n",
    "            if pIDshID_version == 'old':\n",
    "                print('old shID code')\n",
    "                #run old version of the particle ID to subhalo ID conversion\n",
    "                pipe_cell_shIDs = oldpIDshIDconverter(pipe_cell_pIDs,AllPartIDs,AllSubhIDs)\n",
    "                \n",
    "            elif pIDshID_version == 'new':\n",
    "                print('new shID code')\n",
    "                #run the new version of the particle ID to subhalo ID conversion\n",
    "                pipe_cell_shIDs = newpIDshIDconverter(pipe_cell_pIDs,ChunkedPartIDs,ChunkedSubhIDs)\n",
    "                \n",
    "            elif pIDshID_version == 'both':\n",
    "                print('comparing both shID codes')\n",
    "                #run old version of the particle ID to subhalo ID conversion\n",
    "                pipe_cell_shIDs_1 = oldpIDshIDconverter(pipe_cell_pIDs,AllPartIDs,AllSubhIDs)\n",
    "                #run the new version of the particle ID to subhalo ID conversion\n",
    "                pipe_cell_shIDs_2 = newpIDshIDconverter(pipe_cell_pIDs,ChunkedPartIDs,ChunkedSubhIDs)\n",
    "                #compare both versions\n",
    "                array_equal_test = np.array_equal(pipe_cell_shIDs_1,pipe_cell_shIDs_2)\n",
    "                if array_equal_test==True:\n",
    "                    print('Arrays are the same')\n",
    "                else:\n",
    "                    print('error: results are not the same')\n",
    "                    print(pipe_cell_shIDs_1,pipe_cell_shIDs_2)\n",
    "                    break\n",
    "#             ##########################\n",
    "#             ##########################\n",
    "#             ##subhalo ID insert ends##\n",
    "#             ##########################\n",
    "#             ##########################\n",
    "            \n",
    "#             ############################################################\n",
    "#             #For pure Zhang+20 method, exclude all star forming regions#\n",
    "#             ############################################################\n",
    "\n",
    "#             pipe_cell_coords_z = pipe_cell_coords[np.where(pipe_cell_sfr==0)]\n",
    "#             pipe_cell_dens_z = pipe_cell_dens[np.where(pipe_cell_sfr==0)]\n",
    "#             pipe_cell_elab_z = pipe_cell_elab[np.where(pipe_cell_sfr==0)]\n",
    "#             pipe_cell_sfr_z = pipe_cell_sfr[np.where(pipe_cell_sfr==0)]\n",
    "#             pipe_cell_dark_z = pipe_cell_dark[np.where(pipe_cell_sfr==0)]\n",
    "#             pipe_cell_pIDs_z = pipe_cell_pIDs[np.where(pipe_cell_sfr==0)]\n",
    "#             pipe_cell_shIDs_z = pipe_cell_shIDs[np.where(pipe_cell_sfr==0)]\n",
    "\n",
    "#             #print('sum for star forming check: {0}'.format(pipe_cell_sfr_z.sum()))\n",
    "\n",
    "#             #############################################################################################\n",
    "#             #For Pakmor+18 method, apply correction to A for star forming regions and leave no cells out#\n",
    "#             #############################################################################################\n",
    "\n",
    "#             pipe_cell_coords_p = pipe_cell_coords[:]\n",
    "#             pipe_cell_dens_p   = pipe_cell_dens[:]\n",
    "#             pipe_cell_elab_p   = pipe_cell_elab[:]*pipe_cell_warm[:] #perform Pakmor correction\n",
    "#             pipe_cell_sfr_p    = pipe_cell_sfr[:]\n",
    "#             pipe_cell_dark_p   = pipe_cell_dark[:]\n",
    "#             pipe_cell_pIDs_p   = pipe_cell_pIDs[:]\n",
    "#             pipe_cell_shIDs_p  = pipe_cell_shIDs[:]\n",
    "            \n",
    "#             #print(pipe_cell_pIDs_p)\n",
    "#             #print(pipe_cell_shIDs_p)\n",
    "\n",
    "#             ###############################################\n",
    "#             #divide pipe into 10,000 bins along the x-axis#\n",
    "#             ###############################################\n",
    "\n",
    "#             #Question: why 10,000 bins given there are so few particles in the pipe?\n",
    "\n",
    "#             pipe_x_bins = np.linspace(pipe_start_coords[0],pipe_end_coords[0],nbins)\n",
    "#             #print('Pipe x-axis bin coordinates: {0} ckpc/h'.format(pipe_x_bins))\n",
    "\n",
    "#             #######################################\n",
    "#             #get coordinates of center of each bin#\n",
    "#             #######################################\n",
    "\n",
    "#             pipe_bin_coords = np.array([[i,pipe_start_coords[1],pipe_start_coords[2]]for i in pipe_x_bins])\n",
    "\n",
    "\n",
    "#             ###############################################################\n",
    "#             #for each bin, find distance between it and every cell in pipe#\n",
    "#             #find the one with miniimum distance                          #\n",
    "#             #this will be the cell in the los                             #\n",
    "#             #do for zhang (excluding sfr) and non-zhang (including sfr)   #\n",
    "#             ###############################################################\n",
    "\n",
    "\n",
    "#             ###########\n",
    "#             #Pakmor   #\n",
    "#             ###########\n",
    "\n",
    "#             #initialise empty array to hold indices of closest particle to each bin\n",
    "#             nearest_idxs_p = []\n",
    "\n",
    "#             for i in range(len(pipe_bin_coords)): #loop over bins\n",
    "#                 coords = pipe_bin_coords[i] #get bin coordinates\n",
    "#                 distarr = np.sqrt(np.sum(((pipe_cell_coords_p[:]-coords)**2),axis=1)) #create array of distances from cells\n",
    "#                 nearest = np.argmin(distarr) #find nearest cell to bin\n",
    "#                 nearest_idxs_p.append(nearest) #append to array\n",
    "\n",
    "#             nearest_idxs_p = np.array(nearest_idxs_p) #convert to numpy array\n",
    "#             nearest_idxs_unique_p = np.unique(nearest_idxs_p) #some cells are the closest to multiple bins. Get uniques.\n",
    "\n",
    "#             ##############\n",
    "#             #zhang method#\n",
    "#             ##############\n",
    "\n",
    "#             #initialise empty array to hold indices of closest particle to each bin\n",
    "#             nearest_idxs_z = []\n",
    "\n",
    "#             for i in range(len(pipe_bin_coords)): #loop over bins\n",
    "#                 coords = pipe_bin_coords[i] #get bin coordinates\n",
    "#                 distarr = np.sqrt(np.sum(((pipe_cell_coords_z[:]-coords)**2),axis=1)) #create array of distances from cells\n",
    "#                 nearest = np.argmin(distarr) #find nearest cell to bin\n",
    "#                 nearest_idxs_z.append(nearest) #append to array\n",
    "\n",
    "#             nearest_idxs_z = np.array(nearest_idxs_z) #convert to numpy array\n",
    "#             nearest_idxs_unique_z = np.unique(nearest_idxs_z) #some cells are the closest to multiple bins. Get uniques.\n",
    "\n",
    "#             #print('Nearest {0} particle ids: {1}'.format(np.shape(nearest_idxs),nearest_idxs))\n",
    "#             #print('Of these, {0} are unique: {1}'.format(np.shape(nearest_idxs_unique),nearest_idxs_unique))\n",
    "\n",
    "#             #################################\n",
    "#             #extract data from nearest cells#\n",
    "#             #################################\n",
    "\n",
    "#             ###########\n",
    "#             #Pakmor   #\n",
    "#             ###########\n",
    "\n",
    "#             pipe_nearest_coords_p = np.array(pipe_cell_coords_p[nearest_idxs_p]) #coordinates [ckpc/h]\n",
    "#             pipe_nearest_dens_p   = np.array(pipe_cell_dens_p[nearest_idxs_p])   #densities [(1e10Msun/h)/(ckpc/h)**3]\n",
    "#             pipe_nearest_elab_p   = np.array(pipe_cell_elab_p[nearest_idxs_p])   #electron abundance [-]\n",
    "#             pipe_nearest_sfr_p    = np.array(pipe_cell_sfr_p[nearest_idxs_p])    #star formation rate [Msun/yr]\n",
    "#             pipe_nearest_dark_p   = np.array(pipe_cell_dark_p[nearest_idxs_p])   #comoving dark matter density [(1e10Msun/h)/(ckpc/h)**3]\n",
    "#             pipe_nearest_pIDs_p   = np.array(pipe_cell_pIDs_p[nearest_idxs_p])   #particle ID numbers\n",
    "#             pipe_nearest_shIDs_p  = np.array(pipe_cell_shIDs_p[nearest_idxs_p])  #subhalo ID numbers\n",
    "            \n",
    "#             #######\n",
    "#             #zhang#\n",
    "#             #######\n",
    "            \n",
    "#             pipe_nearest_coords_z = np.array(pipe_cell_coords_z[nearest_idxs_z]) #coordinates [ckpc/h]\n",
    "#             pipe_nearest_dens_z   = np.array(pipe_cell_dens_z[nearest_idxs_z])   #densities [(1e10Msun/h)/(ckpc/h)**3]\n",
    "#             pipe_nearest_elab_z   = np.array(pipe_cell_elab_z[nearest_idxs_z])   #electron abundance [-]\n",
    "#             pipe_nearest_sfr_z    = np.array(pipe_cell_sfr_z[nearest_idxs_z])    #star formation rate [Msun/yr]\n",
    "#             pipe_nearest_dark_z   = np.array(pipe_cell_dark_z[nearest_idxs_z])   #comoving dark matter density [(1e10Msun/h)/(ckpc/h)**3] \n",
    "#             pipe_nearest_pIDs_z   = np.array(pipe_cell_pIDs_z[nearest_idxs_z])   #particle ID numbers\n",
    "#             pipe_nearest_shIDs_z  = np.array(pipe_cell_shIDs_z[nearest_idxs_z])  #particle ID numbers\n",
    "            \n",
    "#             #############################################\n",
    "#             #############################################\n",
    "#             ##subhalo central coordinates insert begins##\n",
    "#             #############################################\n",
    "#             #############################################\n",
    "            \n",
    "#             #get first subhalo id\n",
    "#             first_shID = pipe_nearest_shIDs_p[0]\n",
    "            \n",
    "#             #get unique subhalo ids in the pipe\n",
    "#             unique_shIDs = np.unique(pipe_nearest_shIDs_p)\n",
    "            \n",
    "#             #get non- negative one subhalos\n",
    "#             unique_shIDs_notneg1 = np.where(unique_shIDs!=-1)\n",
    "#             unique_shIDs_notneg1 = unique_shIDs[unique_shIDs_notneg1]\n",
    "            \n",
    "#             #get central coordinates for subhalos with non -1 subhalo IDs\n",
    "#             closest_coords = [] #initialise array to store\n",
    "            \n",
    "#             for shID in unique_shIDs_notneg1:\n",
    "#                 print('shid: {0}, snap numberr: {1}'.format(shID,snap_number))\n",
    "#                 gas = il.snapshot.loadSubhalo(basePath, snap_number, shID, 'gas', fields=None)\n",
    "#                 subhalo = il.groupcat.loadSingle(basePath, snap_number, subhaloID=shID)\n",
    "#                 centralpos = subhalo['SubhaloPos']\n",
    "#                 print('shid central pos: {0}'.format(centralpos))\n",
    "                \n",
    "#                 #get coordinates of closest approach to these subhalo IDs\n",
    "#                 placeholder = np.copy(pipe_bin_coords[0]) #placeholder coordinates, y and z will be equal to sightline\n",
    "#                 placeholder[0] = centralpos[0]   #set x position equal to that of subhalo center.\n",
    "#                 print('closest: {0}'.format(placeholder))\n",
    "#                 closest_coords.append(placeholder)\n",
    "#             print('unique subhalo IDs in pipe: {0}'.format(unique_shIDs))\n",
    "#             print('placeholder coordinates for point of closest approach: {0}'.format(closest_coords))\n",
    "            \n",
    "#             ###########################################\n",
    "#             ###########################################\n",
    "#             ##subhalo central coordinates insert ends##\n",
    "#             ###########################################\n",
    "#             ###########################################\n",
    "            \n",
    "#             ###############################################\n",
    "#             #convert density to si units using artale code#\n",
    "#             ###############################################\n",
    "\n",
    "#             pipe_nearest_dens_p_si = TNG_Dens2SI_astropy(pipe_nearest_dens_p)\n",
    "#             pipe_nearest_dens_z_si = TNG_Dens2SI_astropy(pipe_nearest_dens_z)\n",
    "\n",
    "#             ###########################################################\n",
    "#             #convert dark matter density to si units using artale code#\n",
    "#             ###########################################################\n",
    "\n",
    "#             pipe_nearest_dark_p_si = TNG_Dens2SI_astropy(pipe_nearest_dark_p)         \n",
    "#             pipe_nearest_dark_z_si = TNG_Dens2SI_astropy(pipe_nearest_dark_z)         \n",
    "\n",
    "#             #########################################################################\n",
    "#             #divide dark matter density by critical density to create the LSS tracer#\n",
    "#             #########################################################################\n",
    "\n",
    "#             pipe_nearest_LSStracer_p = pipe_nearest_dark_p_si/my_dens_crit\n",
    "#             pipe_nearest_LSStracer_z = pipe_nearest_dark_z_si/my_dens_crit\n",
    "#             #print('The structure tracer array is {0}'.format(pipe_nearest_LSStracer_z))       \n",
    "\n",
    "#             ##########################################\n",
    "#             #Create Large-Scale Structure (LSS) masks#\n",
    "#             ##########################################\n",
    "\n",
    "#             #non-zhang\n",
    "#             voi_mask_PT0_p = pipe_nearest_LSStracer_p < 0.1\n",
    "#             fil_mask_PT0_p = np.logical_and(pipe_nearest_LSStracer_p >= 0.1, pipe_nearest_LSStracer_p < 57)#CELESTE:CORRECTED\n",
    "#             hal_mask_PT0_p = pipe_nearest_LSStracer_p >= 57 \n",
    "\n",
    "#             #zhang\n",
    "#             voi_mask_PT0_z = pipe_nearest_LSStracer_z < 0.1\n",
    "#             fil_mask_PT0_z = np.logical_and(pipe_nearest_LSStracer_z >= 0.1, pipe_nearest_LSStracer_z < 57)#CELESTE:CORRECTED\n",
    "#             hal_mask_PT0_z = pipe_nearest_LSStracer_z >= 57        \n",
    "\n",
    "#             ##############################################################\n",
    "#             #Calculate the number of nearest cells of each structure type#\n",
    "#             ##############################################################\n",
    "\n",
    "#             num_voi_cells_z = np.shape(pipe_nearest_coords_z[voi_mask_PT0_z])[0]\n",
    "#             num_fil_cells_z = np.shape(pipe_nearest_coords_z[fil_mask_PT0_z])[0]\n",
    "#             num_hal_cells_z = np.shape(pipe_nearest_coords_z[hal_mask_PT0_z])[0]\n",
    "\n",
    "#             num_voi_cells_p = np.shape(pipe_nearest_coords_p[voi_mask_PT0_p])[0]\n",
    "#             num_fil_cells_p = np.shape(pipe_nearest_coords_p[fil_mask_PT0_p])[0]\n",
    "#             num_hal_cells_p = np.shape(pipe_nearest_coords_p[hal_mask_PT0_p])[0]\n",
    "\n",
    "#             ##########################################\n",
    "#             #get electron density at each of the bins#\n",
    "#             ##########################################\n",
    "\n",
    "#             #follow zhang+20 equation exactly as native units of TNG are\n",
    "#             #comoving\n",
    "\n",
    "#             #############################################################\n",
    "#             #Zhang: pne = (ElAb)*hmasssfrac*(Dens/protonmass)*((1+z)**3)#\n",
    "#             #use data which excludes SFRs                               #\n",
    "#             #############################################################\n",
    "\n",
    "#             #total\n",
    "#             pipe_nearest_pne_z = (pipe_nearest_elab_z)*hmassfrac*(pipe_nearest_dens_z_si/protonmass)*((1+header['Redshift'])**3)\n",
    "#             pipe_nearest_pne_p = (pipe_nearest_elab_p)*hmassfrac*(pipe_nearest_dens_p_si/protonmass)*((1+header['Redshift'])**3)\n",
    "#             #print('pnes are: {0}'.format(pipe_nearest_pne_z))\n",
    "\n",
    "#             #halos\n",
    "#             pipe_nearest_pne_z_hal = (pipe_nearest_elab_z[hal_mask_PT0_z])*hmassfrac*(pipe_nearest_dens_z_si[hal_mask_PT0_z]/protonmass)*((1+header['Redshift'])**3)\n",
    "#             pipe_nearest_pne_p_hal = (pipe_nearest_elab_z[hal_mask_PT0_p])*hmassfrac*(pipe_nearest_dens_p_si[hal_mask_PT0_p]/protonmass)*((1+header['Redshift'])**3)\n",
    "#             #print('pnes in halos are: {0}'.format(pipe_nearest_pne_z_hal))\n",
    "\n",
    "#             #filaments\n",
    "#             pipe_nearest_pne_z_fil = (pipe_nearest_elab_z[fil_mask_PT0_z])*hmassfrac*(pipe_nearest_dens_z_si[fil_mask_PT0_z]/protonmass)*((1+header['Redshift'])**3)\n",
    "#             pipe_nearest_pne_p_fil = (pipe_nearest_elab_p[fil_mask_PT0_p])*hmassfrac*(pipe_nearest_dens_p_si[fil_mask_PT0_p]/protonmass)*((1+header['Redshift'])**3)\n",
    "#             #print('pnes in filaments are: {0}'.format(pipe_nearest_pne_z_fil))\n",
    "\n",
    "#             #voids\n",
    "#             pipe_nearest_pne_z_voi = (pipe_nearest_elab_z[voi_mask_PT0_z])*hmassfrac*(pipe_nearest_dens_z_si[voi_mask_PT0_z]/protonmass)*((1+header['Redshift'])**3)\n",
    "#             pipe_nearest_pne_p_voi = (pipe_nearest_elab_z[voi_mask_PT0_p])*hmassfrac*(pipe_nearest_dens_p_si[voi_mask_PT0_p]/protonmass)*((1+header['Redshift'])**3)\n",
    "#             #print('pnes in voids are: {0}'.format(pipe_nearest_pne_z_voi))\n",
    "\n",
    "\n",
    "#             ######################################################################\n",
    "#             #Non-zhang: pne = (ElAb*Warm)*hmasssfrac*(Dens/protonmass)*((1+z)**3)#\n",
    "#             #use all data (sfr included) and warm mass fraction                  #\n",
    "#             ######################################################################    \n",
    "\n",
    "#             ##################################\n",
    "#             #average these electron densities#\n",
    "#             ##################################\n",
    "\n",
    "#             #Zhang method/Pakmor method\n",
    "\n",
    "#             #total\n",
    "#             pipe_average_pne_z = np.mean(pipe_nearest_pne_z)\n",
    "#             pipe_average_pne_p = np.mean(pipe_nearest_pne_p)\n",
    "#             #print('Average pne is: {0}'.format(pipe_average_pne_z))   \n",
    "\n",
    "#             #halos\n",
    "#             pipe_average_pne_z_hal = np.sum(pipe_nearest_pne_z_hal)/nbins\n",
    "#             pipe_average_pne_p_hal = np.sum(pipe_nearest_pne_p_hal)/nbins\n",
    "#             #print('Average pne in halos is: {0}'.format(pipe_average_pne_z_hal))\n",
    "\n",
    "#             #filaments\n",
    "#             pipe_average_pne_z_fil = np.sum(pipe_nearest_pne_z_fil)/nbins\n",
    "#             pipe_average_pne_p_fil = np.sum(pipe_nearest_pne_p_fil)/nbins\n",
    "#             #print('Average pne in filaments is: {0}'.format(pipe_average_pne_z_fil))\n",
    "\n",
    "#             #voids\n",
    "#             pipe_average_pne_z_voi = np.sum(pipe_nearest_pne_z_voi)/nbins\n",
    "#             pipe_average_pne_p_voi = np.sum(pipe_nearest_pne_p_voi)/nbins\n",
    "#             #print('Average pne in voids is: {0}'.format(pipe_average_pne_z_voi))\n",
    "\n",
    "\n",
    "#             ################################\n",
    "#             #calculate dDM/dz for this pipe#\n",
    "#             ################################\n",
    "\n",
    "#             #outer bit of eq 7\n",
    "#             outer=c.c/cosmosource.H(0)\n",
    "#             #print(outer)\n",
    "\n",
    "#             #E(z) according to paper eq 5\n",
    "#             Ez = np.sqrt((0.3089*((1+header['Redshift'])**(3)))+(0.6911))\n",
    "#             #print(Ez)\n",
    "\n",
    "#             #denominator of eq 7\n",
    "#             denominator = ((1+header['Redshift'])**(2))*Ez\n",
    "\n",
    "#             #remainder of equation 7\n",
    "\n",
    "#             #total\n",
    "#             edens_z = pipe_average_pne_z\n",
    "#             ddmdz_z = outer*edens_z/denominator\n",
    "#             edens_p = pipe_average_pne_p\n",
    "#             ddmdz_p = outer*edens_p/denominator\n",
    "#             #print('dDM/dz = {0}'.format(ddmdz_z.to('pc*cm**(-3)')))\n",
    "\n",
    "#             #halos\n",
    "#             edens_z_hal = pipe_average_pne_z_hal\n",
    "#             ddmdz_z_hal = outer*edens_z_hal/denominator\n",
    "#             edens_p_hal = pipe_average_pne_p_hal\n",
    "#             ddmdz_p_hal = outer*edens_p_hal/denominator\n",
    "\n",
    "#             #filaments\n",
    "#             edens_z_fil = pipe_average_pne_z_fil\n",
    "#             ddmdz_z_fil = outer*edens_z_fil/denominator\n",
    "#             edens_p_fil = pipe_average_pne_p_fil\n",
    "#             ddmdz_p_fil = outer*edens_p_fil/denominator\n",
    "\n",
    "#             #voids\n",
    "#             edens_z_voi = pipe_average_pne_z_voi\n",
    "#             ddmdz_z_voi = outer*edens_z_voi/denominator\n",
    "#             edens_p_voi = pipe_average_pne_p_voi\n",
    "#             ddmdz_p_voi = outer*edens_p_voi/denominator\n",
    "\n",
    "#             ################################\n",
    "#             #append new data to dictionary #\n",
    "#             ################################\n",
    "\n",
    "#             dict_to_edit['dDMdz_Zhang'].append(ddmdz_z.to('pc*cm**(-3)').value) #append total dDM/dz to array in [pc/cc]\n",
    "#             dict_to_edit['dDMdzHalo_Zhang'].append(ddmdz_z_hal.to('pc*cm**(-3)').value) #append Halo value to array in [pc/cc]\n",
    "#             dict_to_edit['dDMdzFilament_Zhang'].append(ddmdz_z_fil.to('pc*cm**(-3)').value) #append Filament value to array in [pc/cc]\n",
    "#             dict_to_edit['dDMdzVoid_Zhang'].append(ddmdz_z_voi.to('pc*cm**(-3)').value) #append Void value to array in [pc/cc]\n",
    "#             dict_to_edit['nHalo_Zhang'].append(num_hal_cells_z) #append number of cells in halos used to get this dDM/dz value to array\n",
    "#             dict_to_edit['nFilament_Zhang'].append(num_fil_cells_z) #append number of cells in filaments used to get this dDM/dz value to array\n",
    "#             dict_to_edit['nVoid_Zhang'].append(num_voi_cells_z) #append number of cells in voids used to get this dDM/dz value to array\n",
    "\n",
    "#             dict_to_edit['dDMdz_Pakmor'].append(ddmdz_p.to('pc*cm**(-3)').value) #append total dDM/dz to array in [pc/cc]\n",
    "#             dict_to_edit['dDMdzHalo_Pakmor'].append(ddmdz_p_hal.to('pc*cm**(-3)').value) #append Halo value to array in [pc/cc]\n",
    "#             dict_to_edit['dDMdzFilament_Pakmor'].append(ddmdz_p_fil.to('pc*cm**(-3)').value) #append Filament value to array in [pc/cc]\n",
    "#             dict_to_edit['dDMdzVoid_Pakmor'].append(ddmdz_p_voi.to('pc*cm**(-3)').value) #append Void value to array in [pc/cc]\n",
    "#             dict_to_edit['nHalo_Pakmor'].append(num_hal_cells_p) #append number of cells in halos used to get this dDM/dz value to array\n",
    "#             dict_to_edit['nFilament_Pakmor'].append(num_fil_cells_p) #append number of cells in filaments used to get this dDM/dz value to array\n",
    "#             dict_to_edit['nVoid_Pakmor'].append(num_voi_cells_p) #append number of cells in voids used to get this dDM/dz value to array\n",
    "\n",
    "#             #edit 09/02/22 for storing information about subhalos along sightline\n",
    "#             dict_to_edit['firstShID'].append(first_shID) #append first subhalo ID number along pipe line of sight\n",
    "#             dict_to_edit['uniqueShIDs'].append(unique_shIDs) #append unique subhalo ID numbers along pipe line of sight\n",
    "#             dict_to_edit['closestCoords'].append(closest_coords) #append closest coordinates along pipe line of sight to these subhalos\n",
    "        \n",
    "#             #########################\n",
    "#             #save updated dictionary#\n",
    "#             #########################\n",
    "#             #np.save('{0}'.format(outfile_name),dict_to_edit)\n",
    "\n",
    "#             ###########################\n",
    "#             #reload updated dictionary#\n",
    "#             ###########################\n",
    "#             dict_to_edit = np.load(outfile_name,allow_pickle=True).tolist()\n",
    "#             print('New length = {0}'.format(len(dict_to_edit['dDMdz_Pakmor'])))\n",
    "\n",
    "#         ###############################\n",
    "#         ##Once snapshot is done, print#\n",
    "#         ###############################\n",
    "\n",
    "#         print('Completed and stored {0}\\n with {1} keys of length {2}\\n'.format(outfile_name,len(dict_to_edit),len(dict_to_edit['dDMdz_Pakmor'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcb0da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a = np.array([0,1,2,3])\n",
    "TF = np.array([False,True,False,True])\n",
    "test_b = np.array([400,5000,60000,70])\n",
    "print(test_a)\n",
    "test_a[TF]=test_b[TF]\n",
    "print(test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9bd30e39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4722    -1 10845 10845 10845 10845 10845 10845 10845 10845 10845 10845\n",
      " 10845 10845 10845 10845 10845 10845 10845 10845 10845 10845 10845 10845\n",
      " 10845 10845 10845 10845 10845 10845 10845    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1]\n"
     ]
    }
   ],
   "source": [
    "print(newpIDshIDconverter(pipe_cell_pIDs,ChunkedPartIDs,ChunkedSubhIDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "355365a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4722    -1 10845 10845 10845 10845 10845 10845 10845 10845 10845 10845\n",
      " 10845 10845 10845 10845 10845 10845 10845 10845 10845 10845 10845 10845\n",
      " 10845 10845 10845 10845 10845 10845 10845    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "    -1]\n"
     ]
    }
   ],
   "source": [
    "print(oldpIDshIDconverter(pipe_cell_pIDs,AllPartIDs,AllSubhIDs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1002ae70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
